{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Нейронные сети.\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "Мы уверены, что выполнение лабораторных работ занимает значительное время, поэтому не рекомендуем оставлять их на последний вечер перед сдачей.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "* Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи)\n",
    "* Максимально допустимая оценка за всю работу — 15 баллов\n",
    "* Сдавать задание после указанного срока сдачи нельзя\n",
    "* «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса)\n",
    "* Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник)\n",
    "* Не оцениваются задания с удалёнными формулировкам\n",
    "* Не оценивается лабораторная работа целиком, если она была выложена в открытый источник\n",
    "\n",
    "Обратите внимание, что мы не ставим оценку за просто написанный код, корректная работоспособность которого не подтверждена экспериментами.\n",
    "\n",
    "### Правила сдачи\n",
    "Выполненную работу следует отправить в систему Anytask. Более подробно о системе можно почитать на странице курса. Название отправляемого файла должно иметь следующий формат: Surname_Name_Group_NN.ipynb, где NN — номер лабораторной работы. Например, Kozlova_Anna_CS_01.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Рекуррентные языковые модели\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSj85jp-W-V-Bz8ZBjFJYIkV1TTxQxTMh4iqls_rRt8O-sraL08PA)\n",
    "\n",
    "В этой части домашней работы мы создадим языковую модель на рекуррентных нейросетях (RNN) и заставим её придумывать имена.\n",
    "\n",
    "__Языковая модель__, если вкратце, это модель, которая умеет как предсказывать вероятность некоторого текста. Ее можно использовать также чтобы генерировать текст в соответствии с обученными вероятностями. Задание будет заключаться в том, чтобы научить модель генерировать новые имена, скормив ей для этого 8к существующих.\n",
    "\n",
    "В данном случае в качестве входных данных мы будет работать со строками, которые можно рассматривать как последовательности _символов_: $\\{x_0, x_1, x_2, ..., x_n\\}$. \n",
    "\n",
    "Наша основная задача — научиться предсказывать вероятность следующего символа:\n",
    "$$ p(x_0, x_1, x_2, ..., x_n) = \\prod_t p(x_t | x_0, ... x_{t - 1}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "\n",
    "Мы будем строить языковую модель по ~8k человеческих имён на латинице. Если когда-нибудь вам нужно будет дать имя своему ребёнку, у вас будет для этого генеративная нейросетевая модель.\n",
    "\n",
    "Давайте их прочитаем:\n",
    "* Считайте все строки из файла `./names` в список\n",
    "* В начало каждой строки допишите __пробел__\n",
    "* В конце сроки не должно быть переноса (`\\n`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open('./names', 'r') as file:\n",
    "    names = file.readlines()\n",
    "\n",
    "#add space and remove \\n\n",
    "for i, name in enumerate(names):\n",
    "    names[i] = start_token + name[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert all(line[0] == start_token for line in names)\n",
    "assert all(line[-1] != '\\n' for line in names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте, что все корректно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 16\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "assert MAX_LENGTH == 16 , \"max length (for names) should be 16. remove assert if you work on different dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Словари\n",
    "\n",
    "В начале нам будет необходимо построить \"словарь\" — упорядоченное множество уникальных символов, которые сеть может породить. Это нужно, чтобы уметь сопоставить каждому символу свой номер. Перед отправкой в сеть все символы будут кодироваться их номерами в словаре.\n",
    "\n",
    "Также необходимо добавить в словарь пробельный символ, который будет использоваться в качестве специального токена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "tokens = np.unique(list(''.join(names)))\n",
    "\n",
    "tokens = sorted(list(tokens))\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь построим обратный словарь: для каждой буквы посчитаем её номер в списке токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = dict(zip(tokens, np.arange(n_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И проверим, все ли корректно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кажется заработало...\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"число токенов должно совпадать\"\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    if token_to_id[tokens[i]] != i:\n",
    "        print(i)\n",
    "    assert token_to_id[tokens[i]] == i, \"словарь должен указывать на индекс буквы в tokens\"\n",
    "\n",
    "print(\"Кажется заработало...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имея построенное соответствие, можно преобразовать батч входных данных в матрицу int32 номеров токенов. Так как в батче все строки должны быть одной длины, слишком короткие строки в батче нужно будет дополнить пробелами (паддинг)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = names\n",
    "def to_matrix(lines, max_len=None, pad=token_to_id[' '], dtype='int32'):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.get, lines[i]))\n",
    "        lines_ix[i, :len(line_ix)] = line_ix\n",
    "\n",
    "    return lines_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[ 0  3 30 29 35 29 33 40  0]\n",
      " [ 0  9 40 43 46 53  0  0  0]\n",
      " [ 0 18 46 37 47 47 37 33  0]\n",
      " [ 0  9 37 43 50 29 42 42 33]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Один шаг RNN\n",
    "\n",
    "Рекуррентная нейронная сеть (RNN) — это такая сеть с <s>блокнотом</s> состоянием $h$, в который она умеет писать то, что видела.\n",
    "\n",
    "Сеть начинает с пустого $h_0 = \\vec 0$, после чего текст обрабатывается по одному символу:\n",
    "* $x_t$ — очередной символ, $h_t$ — предыдущее состояние\n",
    "* $h_{t+1} = \\text{get_h_next}(h_t, x_t)$ — новое состояние\n",
    "* $p(x_{t+1} | h_{t+1}) = \\text{get_probs}(h_{t+1})$ — вероятность следующего символа\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/8l4qFF0.png\" width=480>\n",
    "\n",
    "Поскольку $x_t$ это индекс символа в словаре (=натуральное число), то ему можно сопоставить некоторый обучаемый вектор (*embedding*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.1 (0.75 балла)**. Реализуйте вычисление нового состояния *get_h_next* и вероятности следующего символа *get_probs*, после чего напишите код для одного шага рекуррентной сети *rnn_one_step*, как на схеме выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras, keras.layers as L\n",
    "\n",
    "emb_size, rnn_size = 16, 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим слой, который сопоставляет каждому из n_tokens входов свой обучаемый вектор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_x = L.Embedding(n_tokens, emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь инициализируем слой, вычисляющий следующее состояния $[emb(x_t), h_t] \\to h_{t+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предполагаем, что на вход данному слою подается вектор, являющийся конкатенацией состояния и текущего входа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_h_next = L.Dense(units=rnn_size, activation='tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, слой предсказывающий вероятности $h_{t+1} \\to P(x_{t+1}|h_{t+1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как получаем вероятности следующего символа? По сути эти вероятности считаются только на основе текущего состояния. Поэтому на подойдет просто применить к текущему состоянию FC-layer с функцией активации softmax. В итоге хотим получить вектор из вероятностей для каждого символа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_probs = L.Dense(n_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации одного шага RNN реализуйте следующую последовательность действий:\n",
    "1. замените номер символа на его вектор (embedding) (*hint*: возможно, вам потребуется tf.reshape);\n",
    "2. сконкатенируйте вектор входа и предыдущее состояние;\n",
    "3. вычислите следующее состояние сети;\n",
    "4. предскажите вероятности для языковой модели P(x_next | h_next)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):    \n",
    "    x_emb = embed_x(x_t)\n",
    "    concat = L.Concatenate()([x_emb, h_t])\n",
    "    h_next = get_h_next(concat)\n",
    "    output_probs = get_probs(h_next)\n",
    "    return h_next, output_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что все работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder('int32', (None, MAX_LENGTH))\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "# начальное состояние из нулей\n",
    "\n",
    "# h0 = tf.zeros([batch_size, rnn_size])\n",
    "h0 = norm = tf.random_normal([batch_size, rnn_size] , mean=1, stddev=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "h1, p_y1 = rnn_one_step(input_sequence[:, 0], h0)\n",
    "\n",
    "dummy_data = np.arange(MAX_LENGTH * 2).reshape([2, -1])\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "test_h1, test_p_y1 = sess.run([h1, p_y1],  {input_sequence: dummy_data})\n",
    "\n",
    "assert test_h1.shape == (len(dummy_data), rnn_size)\n",
    "assert test_p_y1.shape == (len(dummy_data), n_tokens) and np.allclose(test_p_y1.sum(-1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Много шагов RNN\n",
    "\n",
    "После того как был реализован один шаг нейросети, самое время сделать этих шагов побольше. Самый простой способ это сделать — написать цикл для фиксированного числа шагов (`MAX_LENGTH`).\n",
    "\n",
    "**Задание 3.2 (0.25 балла)**. Реализуйте много шагов рекуррентной сети, на каждом шаге вычисляя следующее состояние RNN, исходя из предыдущего, при этом не забывая про *get_h_next* и *get_probs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_prev = h0\n",
    "predicted_probs = []\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]\n",
    "    # YOUR CODE\n",
    "    h_next, probs_next = rnn_one_step(x_t, h_prev)\n",
    "    # END OF YOUR CODE\n",
    "    predicted_probs.append(probs_next)\n",
    "    h_prev = h_next\n",
    "    \n",
    "predicted_probs = tf.stack(predicted_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert predicted_probs.shape.as_list() == [None, MAX_LENGTH, n_tokens]\n",
    "assert h_prev.shape.as_list() == h0.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение RNN\n",
    "\n",
    "Как и любую вероятностную модель, RNN можно обучить методом максимизации log-правдоподобия по всей выборке $D$:\n",
    "\n",
    "$$ \\theta = \\underset \\theta {argmax} \\log P(D) $$\n",
    "\n",
    "где\n",
    "$$ \\log P(D) = \\underset {\\vec x \\in D} \\sum \\log P(\\vec x) = \\underset {\\vec x \\in D} \\sum \\underset {x_t \\in \\vec x} \\sum \\log P(x_t | x_0, ..., x_{t+1})$$\n",
    "\n",
    "C тем же успехом мы можем __минимизировать__ кроссэнтропию — то же самое, но с минусом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_matrix: (?, 15, 55)\n",
      "answers_matrix: (?, 15, 55)\n"
     ]
    }
   ],
   "source": [
    "predictions_matrix = predicted_probs[:, :-1]\n",
    "answers_matrix = tf.one_hot(input_sequence[:, 1:], n_tokens)\n",
    "\n",
    "print('predictions_matrix:', predictions_matrix.shape)\n",
    "print('answers_matrix:', predictions_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.3 (0.5 балла)**. Реализуйте вычисление функции потерь (кроссэнтропия) и шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = -tf.reduce_sum(tf.multiply(tf.log(predictions_matrix), answers_matrix))\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл обучения\n",
    "\n",
    "**Задание 3.4 (0.5 балла)**. Напишите цикл обучения:\n",
    "1. выбираем `batch_size` случайных строчек\n",
    "2. преобразуем их в матрицу индексов\n",
    "3. вычисляем функцию потерь и делаем шаг обучения\n",
    "4. записываем функцию потерь в `history`\n",
    "\n",
    "Для удобства отладки рекомендуем печатать или рисовать промежуточные результаты раз в несколько итераций.\n",
    "\n",
    "Также постарайтесь обойтись одним `sess.run` на итерацию цикла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 518.3812255859375\n",
      "epoch 1, loss 526.8828125\n",
      "epoch 2, loss 479.41485595703125\n",
      "epoch 3, loss 455.0764465332031\n",
      "epoch 4, loss 490.4927673339844\n",
      "epoch 5, loss 447.1059875488281\n",
      "epoch 6, loss 499.0110168457031\n",
      "epoch 7, loss 456.18414306640625\n",
      "epoch 8, loss 493.78070068359375\n",
      "epoch 9, loss 465.0120849609375\n",
      "epoch 10, loss 481.95330810546875\n",
      "epoch 11, loss 447.781005859375\n",
      "epoch 12, loss 450.1383056640625\n",
      "epoch 13, loss 424.6362609863281\n",
      "epoch 14, loss 420.0716552734375\n",
      "epoch 15, loss 447.4498596191406\n",
      "epoch 16, loss 489.94134521484375\n",
      "epoch 17, loss 460.69403076171875\n",
      "epoch 18, loss 445.2406005859375\n",
      "epoch 19, loss 458.8621520996094\n"
     ]
    }
   ],
   "source": [
    "lines = np.array(lines)\n",
    "\n",
    "batch = 32\n",
    "num_epochs = 20\n",
    "x_size = len(lines)\n",
    "history = []\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for j in range(x_size // batch):\n",
    "        indeces = np.random.choice(np.arange(x_size), batch)\n",
    "        batch_sequence = []\n",
    "        for i, ind in enumerate(indeces):\n",
    "            word = list(map(lambda x: token_to_id[x], lines[ind]))\n",
    "            word += [0] * (MAX_LENGTH - len(word))\n",
    "            batch_sequence.append(word)\n",
    "            \n",
    "        train_loss, _ = sess.run([loss, optimize], {input_sequence:batch_sequence})\n",
    "        \n",
    "        history.append(train_loss)\n",
    "#         print(batch_sequence)\n",
    "    print('epoch {}, loss {}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUh71/9wnKRetgWzZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение RNN\n",
    "\n",
    "Только что у нас обучилась модель, которая предсказывает вероятности следующего символа.\n",
    "Теперь давайте применим её к строке из одного пробела. Получим вероятности первой буквы имени. После чего:\n",
    "* $x_t \\sim P(x_t | h_t)$ — выберем букву пропорционально вероятностям.\n",
    "* $h_{t+1} = \\text{get_h_next}(h_t, x_t)$ — присоединим букву к имени и прогоним через RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала инициализируем необходимые переменные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder('int32', (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_size], 'float32'))\n",
    "\n",
    "next_h, next_probs = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И будем использовать функцию ниже для генерации новых имен!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=' ', max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    sess.run(tf.variables_initializer([h_t]))\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         sess.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs, _ = sess.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что же придумала наша модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " March          \n",
      " Pivelle        \n",
      " Rusy           \n",
      " Karie          \n",
      " Esmet          \n",
      " Hansi          \n",
      " Harmott        \n",
      " Farida         \n",
      " Shamie         \n",
      " Hulla          \n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpetta      \n",
      " Trumpy         \n",
      " Trumpi         \n",
      " Trumpe         \n",
      " Trumpi         \n",
      " Trumpiew       \n",
      " Trumpie        \n",
      " Trumpie        \n",
      " Trumpar        \n",
      " Trumpie        \n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну, получилось прикольно. Никаких комментариев не писала, вроде и так понятно, что нужно делать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что теперь?\n",
    "\n",
    "Если вам наскучит решать повседневные задачи или вам нужны новые идеи, вы теперь всегда можете воспользоваться RNN чтобы сгенерировать что-то новое. Вот несколько задач, от которых можно отталкиваться:\n",
    "* названия статей по глубинному обучению;\n",
    "* названия карт Magic The Gathering;\n",
    "* [имена покемонов](https://github.com/cervoise/pentest-scripts/blob/master/password-cracking/wordlists/pokemon-list-en.txt);\n",
    "* clickbait заголовки;\n",
    "* молекулы в формате [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system);\n",
    "* ваша фантазия, с ограничениями которой вы уже должны были понять как бороться.\n",
    "\n",
    "Если возьмётесь за эту задачу, то вот несколько полезных советов:\n",
    "* Сейчас модель обучается на коротких строчках. Если у вас роман, его придётся порезать на кускочки.\n",
    "* Если длина строк сильно варьируется, можно поставить параметр MAX_LENGTH так, чтобы он покрывал 90%. Это обычно дает ускорение примерно в 2 раза.\n",
    "* Для более сложных задач требуется больше нейронов (rnn_size). Кроме того, можно экспериментировать и со составляющими сети (см. ниже).\n",
    "\n",
    "### Ещё почитать\n",
    "\n",
    "* [Подборка советов](https://danijar.com/tips-for-training-recurrent-neural-networks/) по обучению RNN. Чуть более полезная, чем обычно.\n",
    "* Отличный блог-пост от Andrej Karpathy про языковые модели на rnn, их применение и визуализацию — [Unreasonable Effectiveness of RNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).\n",
    "* Большой список статей, постов, реализаций и прочих полезностей по RNN - [awesome rnn](https://github.com/kjw0612/awesome-rnn).\n",
    "* [Зоопарк](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) готовых рекуррентных ячеек (LSTM, GRU) в TF. И ещё одна реализация [в карасе](https://keras.io/layers/recurrent/).\n",
    "* Сейчас мы настраиваем количество итераций заранее. Если вы хотите определять их динамически, милости просим в [tf.while_loop](https://www.tensorflow.org/api_docs/python/tf/while_loop) или [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan).\n",
    "* А ещё рекуррентные сети можно аугментировать механизмом внимания или долговременной памятью. Вот тут есть [хорошая статья](https://distill.pub/2016/augmented-rnns/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
